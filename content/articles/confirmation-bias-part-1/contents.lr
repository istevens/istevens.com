title: Confirmation Bias, Part 1
---
_hidden: no
---
pub_date: 2019-05-01
---
author: Ian Stevens
---
dek: Dek goes here
---
body:

!! A while back I volunteered to contribute to a book on the behaviours and
history of political, legal, and socio-economic systems. It was to be a primer
for those creating products with the potential to disrupt those systems. My contribution was a chapter on
confirmation bias, detailing its effects, its workings, and how it can be
overcome. Though the book was never published, my research had me reconsidering my
behaviour. Always careful with my words, I started speaking even more purposefully,
not wanting to pass bias on to others. The experience had such an impact that I
couldn't let my chapter sit unread, and split it into three articles. This is the first
of the three, describing the pernicious influence of confirmation bias. The
other two explain how it grows and spreads, and what we can do to fight it.

Suppose you learned of a disease which causes people to behave irrationally.
Infected adults make bad judgments of others' ability. Girls as
young as six with the disease start to view women as less smart than
men. [Another?]

The symptoms are real, but the disease is not. If it were, there
might be a cure — or at least a way to slow the contagion. There
isn't — it's us, and almost everyone on Earth is affected.

<aside>Confirmation bias leads us to hold false beliefs with a confidence greater than evidence can justify.</aside>

[This affliction is hard-wired in our brains — an involuntary mental
"short cut". — remove?] You may know it as _confirmation bias_, one of many
cognitive or unconscious biases which affect how we reason. Unlike a leaning or a
slant, like left- or right-wing bias, cognitive biases are the
result of involuntary mental "short-cuts". [For example, we often use
stereotypes to fill in details – rarely accurately — about a member
of a specific group. — cut or clarify?] These short-cuts may have helped our ancestors
quickly tell friend from foe [false negatives?], but they impede logic and accuracy
necessary in our modern world. [^NELSON2015]

[summarize tendencies, possibly chart or infographic] There are many cognitive biases and confirmation bias likely does us the
most harm, tricking us into accepting untruths and nurturing them
until we're certain they're true. It leads us to hold false
beliefs with a confidence greater than evidence can justify.
[^NICKERSON1998] Those affected will often misinterpret new
information as supporting a previously-held belief. [^RABIN1999]
[Thanks to confirmation bias we may readily observe and recall
unusual behaviours in people from distinct ethnicities. This
tendency, left unchecked, can contribute to racist stereotypes.
[^NICKERSON1998] — awkward, out-of-place]

Before confirmation bias had a name, people were thought to be largely
rational. Errors in judgment were often blamed on weak
reasoning. [^LARRICK2004] In his recount of the Peloponnesian War almost 2500 years ago, historian Thucydides
called confirmation bias a "habit":

> "… and their judgment was based more upon blind wishing than upon any sound
> prediction; for it is a habit of mankind to entrust to careless hope what
> they long for, and to use sovereign reason to thrust aside what they do not
> desire."
>
> [Thucydides, 460BC&#x2011;395BC](https://en.wikiquote.org/wiki/Thucydides#Book_IV)

Over 400 years ago, Sir Francis Bacon was more inclined to treat confirmation bias as a
trick of the mind:

> "The human understanding when it has once adopted an opinion […]
> draws all things else to support and agree with it. And though there be a greater
> number and weight of instances to be found on the other side, yet these it
> either neglects and despises, or else by some distinction sets aside and
> rejects, in order that […] its former conclusions may remain inviolate."
>
> [Sir Francis Bacon, 1561&#x2011;1626](https://en.wikiquote.org/wiki/Francis_Bacon#Book_I)

It wasn't until 1960, when psychologist Peter Wason performed his first
selection experiment, that confirmation bias finally had a name.

<figure>
<img src="wason.svg"/>
<figcaption>Wason's selection experiment</figcaption>
</figure>

Wason's experiment was simple: present a person with three numbers (eg.
2-4-6), and ask them to guess the rule for those numbers. That
person was next asked to pick three other numbers which fit their
hypothesis, and were then told whether those numbers fit the
_actual_ rule. [Give example] The actual rule was always "any
ascending sequence", but participants often came up with rules
specific to their initial triplet (eg. "numbers increasing by two"
in the case of 2-4-6). They then tended to pick triplets which confirmed
their rule (eg. 9-11-13), and rarely triplets which would show it to
be wrong (eg. 9-10-11). As we'll learn later, improper selection of
evidence is one tendency which contributes to confirmation bias.

Confirmation bias can change the way we view reality. As with the
Wason experiment, we may only see what our beliefs lead us to
expect. We may also add weight to information or events which support
our theories, and discount information which does not. Bias also
causes us to filter out opposing views and supporting facts, leading
to over-confidence in our beliefs. Over-confidence, in turn, can lead
us to bad choices, sometimes resulting in risky and extreme
behaviour. [^RABIN1999]

Horoscopes are a mild example of how bias can affect our behaviour. No
doubt you know someone who, in some small way, has acted on advice from a
horoscope or a psychic. Indeed, such mediums remain popular largely
*because* we tend to focus on or remember what we expect or desire.
People also feel that universally positive traits [like…?] apply to
them, without considering how widespread those traits really
are. This opens us to place faith in astrology, fortune-tellers, and con
artists, who — knowingly or not — appeal to those traits so that we recognize
ourselves in their "predictions".  We often want to believe such people,
focusing on and remembering when they are right, not when they are wrong.
[^NICKERSON1998]

[examples?]

This same tendency to see or remember what we expect or desire can also feed
more serious conditions such as hypochondria and paranoia. Depressed people
may also focus on information which strengthens their depression, and ignore
more positive information which may help them. [^NICKERSON1998]

[Chart of tendencies?]

Tendencies contributing to confirmation bias can lead us to confidently make bad
decisions which affect ourselves and others. Maybe you know
someone — a friend or relative — who seems to have nothing good to
say about a particular group. Have they gone out of their way to
avoid a member of that group? or treated someone in that group
differently than they would others? Such stereotypes and prejudices
are largely fed by confirmation bias, and can influence how we treat
or view "others". [Tie back to "friend and foe".]

[Shorter, leaner paragraph] The selective memory behind our tendency to see what we are led to
expect can be detrimental to our opinion of people or groups.  It
can confirm our belief, and lead us to more readily recall unusual
behaviour from distinct groups. Belief tainted by memory increases
our confidence in stereotypes, leading us to more likely act on
them. [^NELSON2015] Thinking back to a group you [Provide distance with bigot relative?] may mistrust, which
negative behaviours do you associate with that group? How about
positive or benign ones? Several studies have shown how bias can
change our reactions to people about whom we hold stereotypes — even
if we are only *told* those people belong to a specific group.
[^NICKERSON1998]

<aside>The tendency to make biased decisions based on confidence
in a stereotype isn't born of years of prejudicial thinking</aside>

In one such study, participants were shown a video of a girl playing. Half
were told the girl's parents were college-educated with white-collar jobs.
These people were shown the girl playing in a well-to-do suburban
neighbourhood. The other participants were told the girl's parents were
high-school graduates with blue-collar jobs, and were shown her playing
in a poor urban neighbourhood. People in each of those groups were then shown
the same video of the girl answering a series of questions, and were asked to
evaluate her reading level. The group which was told the girl was from
a well-to-do suburban family rated her reading level significantly higher
than the group which was told she was from a poorer neighbourhood. Both
groups saw the same Q&A video, were given no other information, yet reached
different conclusions because of how they felt about where the girl lived. [^RABIN1999]

[Awkward?] This tendency to make biased decisions based on confidence
in a stereotype isn't born of years of prejudicial thinking,
either. In a similar study, 5-7 year-olds were told
of a person who was "really, really smart." The children were then
shown a picture of four adults — two women and two men — and were asked
to pick the "really, really smart" one. At aged 5, boys and girls
chose their own gender roughly equally. Girls aged 6 or 7, however,
were significantly less likely than boys the same age to view their
own gender positively. In another study with different children,
boys and girls aged 6 or 7 were asked to comment on a game for
"really, really smart" children or one for children who "try really,
really hard." The girls were significantly less interested than the
boys in games for "really, really smart" children. [^BIAN2017]

[Picture illustrating above?]

Like Thucydides, we may feel our reasoning is
stronger than others', and that we wouldn't fall into the "habit" of
misjudging people, especially a child, so easily. Yet even people
who have studied reasoning and statistics can still have a problem
with confirmation bias and stereotypes. [For instance, numerous
peer-reviewed studies claim to show that women are less likely than
men to take on risk. However, a 2013 "study of studies" claims that
these studies and their authors are likely affected by stereotypes
induced by bias. [^NELSON2015] The studies' authors reached
inaccurate conclusions by falling prey to a number of tendencies
behind confirmation bias. — cut or better wording]

<aside>We don't see our bias because we feel we're being
reasonable. We are, but with skewed information.</aside>

[Cut or sum with ref to tendencies to bias? — Some studies on risk and gender reinforce existing gender stereotypes by
inaccurately citing conclusions of earlier literature, or emphasizing results
agreeing with stereotypes, while downplaying or not reporting results which
do not. These confirming results are, in turn, more likely to be published. In
other studies, confounding variables (some due to socialization and pressure to
conform to gender expectations) were neglected. In others, areas where women
naturally take on a great deal of risk (such as with child birth, and risk of
domestic violence) were neglected. Instead, different areas of risk (such as
finance) were studied and findings extrapolated to a broader context.
[^NELSON2015] In the following paragraphs, we'll learn how tendencies such as
over-weighing instances of positive confirmation can cause confirmation bias to grow
and persist. Because we often pair these tendencies with internally coherent
patterns of reasoning, few are immune.]

Since Wason's experiment, many studies have shown that not only do we hold
biases, they can be difficult to correct. [^LARRICK2004] We
may not even know about our own confirmation bias. Worse, although our
reasoning about information may be biased, we still rationally apply that data to our
own state of the world. We don't see our bias because we feel we're being
reasonable. We are, but with skewed information. This bias-influenced reasoning may
make sense to us, but it results in imperfect decisions. Ignorant to our bias,
we may become over-confident in our beliefs and risk tainting future reasoning,
thereby reinforcing our bias. [^JONES2000] [^RABIN1999]

Confirmation bias exists and negatively influences human behaviour — so now
what? We can correct our own bias. Awareness helps a great deal, as it turns
out. There are also habits we can pick up to better keep our bias in check.
That's in part three of this series. Our next step is to gain a better
understanding of how confirmation bias grows and spreads, which brings us to
part two.

[^JONES2000]: Jones, M., and Sugden, R. (2000). Positive confirmation bias in the acquisition of information. (Dundee Discussion Papers in Economics; No.  115). University of Dundee.

[^LARRICK2004]: Larrick, R. P. (2004) Debiasing, in Blackwell Handbook of Judgment and Decision Making (eds D. J. Koehler and N. Harvey), Blackwell Publishing Ltd, Malden, MA, USA.

[^NELSON2015]: Nelson, J. A. (2015), Are women really more risk-averse than men? A re-analysis of the literature using expanded methods. Journal of Economic Surveys, 29: 566-585.

[^NICKERSON1998]: Nickerson, J. S. (1998). Confirmation bias: a ubiquitous phenomenon in many guises. Review of General Psychology, Vol. 2, No. 2, pp. 175-220.

[^RABIN1999]: Rabin, Matthew and Schrag, Joel L., (1999), First Impressions Matter: A Model of Confirmatory Bias, The Quarterly Journal of Economics, 114, issue 1, p. 37-82.
---
_discoverable: no
